{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on `emnist`\n",
    "\n",
    "## 1. Create `Readme.md` to document your work\n",
    "\n",
    "Explain your choices, process, and outcomes.\n",
    "\n",
    "## 2. Classify letters a->g\n",
    "\n",
    "### Subset the data\n",
    "\n",
    "Select only the lowercase letters (a, b, ..., g) for classification\n",
    "\n",
    "### Choose a model\n",
    "\n",
    "Your choice of model! Choose wisely...\n",
    "\n",
    "### Train away!\n",
    "\n",
    "Is do you need to tune any parameters? Is the model expecting data in a different format?\n",
    "\n",
    "\n",
    "### Evaluate the model\n",
    "\n",
    "Evaluate the models on the test set, analyze the confusion matrix to see where the model performs well and where it struggles.\n",
    "\n",
    "### Investigate subsets\n",
    "\n",
    "On which classes does the model perform well? Poorly? Evaluate again, excluding easily confused symbols (such as 'O' and '0').\n",
    "\n",
    "### Improve performance\n",
    "\n",
    "Brainstorm for improving the performance. This could include trying different architectures, adding more layers, changing the loss function, or using data augmentation techniques.\n",
    "\n",
    "## 2. Classify digits vs. letters model showdown\n",
    "\n",
    "Perform a full showdown classifying digits vs letters:\n",
    "\n",
    "1. Create a column for whether each row is a digit or a letter\n",
    "2. Choose an evaluation metric \n",
    "3. Choose several candidate models to train\n",
    "4. Divide data to reserve a validation set that will NOT be used in training/testing\n",
    "5. K-fold train/test\n",
    "    1. Create train/test splits from the non-validation dataset \n",
    "    2. Train each candidate model (best practice: use the same split for all models)\n",
    "    3. Apply the model the the test split \n",
    "    4. (*Optional*) Perform hyper-parametric search\n",
    "    5. Record the model evaluation metrics\n",
    "    6. Repeat with a new train/test split\n",
    "6. Promote winner, apply model to validation set\n",
    "7. (*Optional*) Perform hyper-parametric search, if applicable\n",
    "8. Report model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "####PROBLEM 1\n",
    "#data preparation, create training and testing and combine them in the end \n",
    "# Import packages\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emnist\n",
    "from IPython.display import display,Markdown\n",
    "from hashlib import sha1\n",
    "from sklearn.model_selection import train_test_split\n",
    "#load the eminst data\n",
    "# Load the data, and reshape it into a 28x28 array\n",
    "\n",
    "# The size of each image is 28x28 pixels\n",
    "size = 28 \n",
    "\n",
    "# Extract the training split as images and labels\n",
    "image, label = emnist.extract_training_samples('byclass')\n",
    "\n",
    "# Add columns for each pixel value (28x28 = 784 columns)\n",
    "raw_train = pd.DataFrame()\n",
    "\n",
    "# Add a column showing the label\n",
    "raw_train['label'] = label\n",
    "\n",
    "# Add a column with the image data as a 28x28 array\n",
    "raw_train['image'] = list(image)\n",
    "\n",
    "\n",
    "# Repeat for the test split\n",
    "image, label = emnist.extract_test_samples('byclass')\n",
    "raw_test = pd.DataFrame()\n",
    "raw_test['label'] = label\n",
    "raw_test['image'] = list(image)\n",
    "raw = pd.concat([raw_train,raw_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the data only for a,b,c,d,e,f,g for classification, which corresponds to the label 36-42\n",
    "raw_lowercase = raw[(raw[\"label\"] > 35.9) & (raw[\"label\"] < 42.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zi Li\\AppData\\Local\\Temp\\ipykernel_21856\\2592636757.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_lowercase['letter'] = raw_lowercase['label'].apply(classify_value)\n"
     ]
    }
   ],
   "source": [
    "#choose random forest to train the model, for multi class classfication \n",
    "def classify_value(x):\n",
    "    if x == 36:\n",
    "        return 'a'\n",
    "    elif x ==37:\n",
    "        return 'b'\n",
    "    elif x ==38:\n",
    "        return 'c'\n",
    "    elif x ==39:\n",
    "        return 'd'\n",
    "    elif x ==40:\n",
    "        return 'e'\n",
    "    elif x ==41:\n",
    "        return 'f'\n",
    "    else:\n",
    "        return 'g'\n",
    "raw_lowercase['letter'] = raw_lowercase['label'].apply(classify_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data set into 75% training set and 25% testing set\n",
    "raw_lowercase_training,raw_lowercase_testing = train_test_split(raw_lowercase,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lowercase_training['image_flat'] = raw_lowercase_training['image'].apply(lambda x: np.array(x).reshape(-1))\n",
    "raw_lowercase_testing['image_flat'] = raw_lowercase_testing['image'].apply(lambda x: np.array(x).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for performance metrics\n",
    "metrics_dict = {}\n",
    "metrics_dict = {\n",
    "    'a_vs_b_vs_c_vs_d_vs_e_vs_e_vs_f_vs_g' : { # task name (classifier for multiple class)\n",
    "    \n",
    "        'xgboost': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'neural_network': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(task, model_name, metrics_dict):\n",
    "    \"\"\"Display performance metrics and confusion matrix for a model.\"\"\"\n",
    "    metrics_df = pd.DataFrame()\n",
    "    cm_df = pd.DataFrame()\n",
    "    for key, value in metrics_dict[task][model_name].items():\n",
    "        if type(value) == np.ndarray:\n",
    "            #cm_df = pd.DataFrame(value, index=['actual 0', 'actual 1'], columns=['predicted 0', 'predicted 1'])\n",
    "            cm_df = pd.DataFrame(value, index=['actual a', 'actual b', 'actual c', 'actual d', 'actual e', 'actual f', 'actual g'], \n",
    "                                 columns=['predicted a', 'predicted b','predicted c','predicted d','predicted e','predicted f','predicted g'])\n",
    "        else:\n",
    "            metrics_df[key] = [value]\n",
    "    display(Markdown(f'# Performance Metrics: {model_name}'))\n",
    "    display(metrics_df)\n",
    "    display(Markdown(f'# Confusion Matrix: {model_name}'))\n",
    "    display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "      <th>letter</th>\n",
       "      <th>image_flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37560</th>\n",
       "      <td>36</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>a</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418122</th>\n",
       "      <td>40</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141802</th>\n",
       "      <td>36</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>a</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555998</th>\n",
       "      <td>40</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221913</th>\n",
       "      <td>40</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450241</th>\n",
       "      <td>36</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>a</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386906</th>\n",
       "      <td>40</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564070</th>\n",
       "      <td>36</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>a</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265754</th>\n",
       "      <td>40</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50332</th>\n",
       "      <td>40</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>e</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51596 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                              image letter  \\\n",
       "37560      36  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      a   \n",
       "418122     40  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      e   \n",
       "141802     36  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      a   \n",
       "555998     40  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      e   \n",
       "221913     40  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      e   \n",
       "...       ...                                                ...    ...   \n",
       "450241     36  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      a   \n",
       "386906     40  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      e   \n",
       "564070     36  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      a   \n",
       "265754     40  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      e   \n",
       "50332      40  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      e   \n",
       "\n",
       "                                               image_flat  \n",
       "37560   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "418122  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "141802  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "555998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "221913  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "450241  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "386906  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "564070  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "265754  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50332   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[51596 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw_lowercase_training = raw_lowercase_training.head(100000)\n",
    "#raw_lowercase_testing = raw_lowercase_testing.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960288</td>\n",
       "      <td>0.955751</td>\n",
       "      <td>0.928545</td>\n",
       "      <td>0.941047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.960288   0.955751  0.928545  0.941047"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted a</th>\n",
       "      <th>predicted b</th>\n",
       "      <th>predicted c</th>\n",
       "      <th>predicted d</th>\n",
       "      <th>predicted e</th>\n",
       "      <th>predicted f</th>\n",
       "      <th>predicted g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual a</th>\n",
       "      <td>2787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual b</th>\n",
       "      <td>13</td>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual c</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual d</th>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2905</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual e</th>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>7073</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual f</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>725</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual g</th>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted a  predicted b  predicted c  predicted d  predicted e  \\\n",
       "actual a         2787            3            1           20           35   \n",
       "actual b           13         1444            0           22           11   \n",
       "actual c           23            1          667            4          106   \n",
       "actual d           50           19            1         2905            8   \n",
       "actual e           51            6           24            8         7073   \n",
       "actual f            5            5            2           17           18   \n",
       "actual g          106            2            3           12           16   \n",
       "\n",
       "          predicted f  predicted g  \n",
       "actual a            3           19  \n",
       "actual b            6            4  \n",
       "actual c            5            1  \n",
       "actual d            6            8  \n",
       "actual e           10            7  \n",
       "actual f          725           13  \n",
       "actual g            9          915  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "task = 'a_vs_b_vs_c_vs_d_vs_e_vs_f_vs_g'\n",
    "model_name = 'random_forest'\n",
    "metrics_dict[task] = {model_name: {}}\n",
    "\n",
    "# Initialize random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(raw_lowercase_training['image_flat'].tolist(), raw_lowercase_training['letter'])\n",
    "y_pred = rf_clf.predict(raw_lowercase_testing['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(raw_lowercase_testing['letter'], y_pred)\n",
    "prec = precision_score(raw_lowercase_testing['letter'], y_pred,average='macro')\n",
    "rec = recall_score(raw_lowercase_testing['letter'], y_pred,average='macro')\n",
    "f1 = f1_score(raw_lowercase_testing['letter'], y_pred,average='macro')\n",
    "cm = confusion_matrix(raw_lowercase_testing['letter'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the confusion matrix, the model has good predictions in a, b,d,e and f, but with bad predictions in c and g. Therefore, the next step is to remove c and g to see \n",
    "#if works better. The overall accruary is pretty good. \n",
    "raw_lowercase_training = raw_lowercase_training[raw_lowercase_training[\"letter\"].isin([\"a\",\"b\",\"d\",\"e\",\"f\" ])]\n",
    "raw_lowercase_testing = raw_lowercase_testing[raw_lowercase_testing[\"letter\"].isin([\"a\",\"b\",\"d\",\"e\",\"f\" ])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977428</td>\n",
       "      <td>0.97189</td>\n",
       "      <td>0.967371</td>\n",
       "      <td>0.969563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.977428    0.97189  0.967371  0.969563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted a</th>\n",
       "      <th>predicted b</th>\n",
       "      <th>predicted d</th>\n",
       "      <th>predicted e</th>\n",
       "      <th>predicted f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual a</th>\n",
       "      <td>2798</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual b</th>\n",
       "      <td>15</td>\n",
       "      <td>1447</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual d</th>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>2905</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual e</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7096</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual f</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted a  predicted b  predicted d  predicted e  predicted f\n",
       "actual a         2798            2           24           41            3\n",
       "actual b           15         1447           20           11            7\n",
       "actual d           60           18         2905            7            7\n",
       "actual e           56            6           10         7096           11\n",
       "actual f            5            7           20           16          737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use random forest to test the test data again \n",
    "#using random forest\n",
    "def display_metrics(task, model_name, metrics_dict):\n",
    "    \"\"\"Display performance metrics and confusion matrix for a model.\"\"\"\n",
    "    metrics_df = pd.DataFrame()\n",
    "    cm_df = pd.DataFrame()\n",
    "    for key, value in metrics_dict[task][model_name].items():\n",
    "        if type(value) == np.ndarray:\n",
    "            #cm_df = pd.DataFrame(value, index=['actual 0', 'actual 1'], columns=['predicted 0', 'predicted 1'])\n",
    "            cm_df = pd.DataFrame(value, index=['actual a', 'actual b', 'actual d', 'actual e', 'actual f'], \n",
    "                                 columns=['predicted a', 'predicted b','predicted d','predicted e','predicted f'])\n",
    "        else:\n",
    "            metrics_df[key] = [value]\n",
    "    display(Markdown(f'# Performance Metrics: {model_name}'))\n",
    "    display(metrics_df)\n",
    "    display(Markdown(f'# Confusion Matrix: {model_name}'))\n",
    "    display(cm_df)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "task = 'a_vs_b_vs_c_vs_d_vs_e_vs_f_vs_g'\n",
    "model_name = 'random_forest'\n",
    "metrics_dict[task] = {model_name: {}}\n",
    "\n",
    "# Initialize random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(raw_lowercase_training['image_flat'].tolist(), raw_lowercase_training['letter'])\n",
    "y_pred = rf_clf.predict(raw_lowercase_testing['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(raw_lowercase_testing['letter'], y_pred)\n",
    "prec = precision_score(raw_lowercase_testing['letter'], y_pred,average='macro')\n",
    "rec = recall_score(raw_lowercase_testing['letter'], y_pred,average='macro')\n",
    "f1 = f1_score(raw_lowercase_testing['letter'], y_pred,average='macro')\n",
    "cm = confusion_matrix(raw_lowercase_testing['letter'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after removing poor predictions of c and g, the model works slightly better. In general, random forest works very good in binary outcome classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PROBLEM 2\n",
    "\n",
    "#data preparation, create training and testing and combine them in the end \n",
    "# Import packages\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emnist\n",
    "from hashlib import sha1\n",
    "from IPython.display import display,Markdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "#load the eminst data\n",
    "# Load the data, and reshape it into a 28x28 array\n",
    "\n",
    "# The size of each image is 28x28 pixels\n",
    "size = 28 \n",
    "\n",
    "# Extract the training split as images and labels\n",
    "image, label = emnist.extract_training_samples('byclass')\n",
    "\n",
    "# Add columns for each pixel value (28x28 = 784 columns)\n",
    "raw_train = pd.DataFrame()\n",
    "\n",
    "# Add a column showing the label\n",
    "raw_train['label'] = label\n",
    "\n",
    "# Add a column with the image data as a 28x28 array\n",
    "raw_train['image'] = list(image)\n",
    "\n",
    "\n",
    "# Repeat for the test split\n",
    "image, label = emnist.extract_test_samples('byclass')\n",
    "raw_test = pd.DataFrame()\n",
    "raw_test['label'] = label\n",
    "raw_test['image'] = list(image)\n",
    "raw = pd.concat([raw_train,raw_test],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for weather each row is a digit or letter\n",
    "raw[\"class\"] = pd.cut(raw['label'], bins=[-0.1, 9.1,61.1], labels=[0, 1])   #0 for digit and 1 for letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose an evaluation metric\n",
    "#accuracy,precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose several candidate models to train: decision tree, Naive Bayes, support vector machine, random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devide data to reserve a validation set that will not be used in training/testing \n",
    "#25% for the validation set, 75% for non-validation set(50% for training, 25% for testing)\n",
    "validation,non_validation = train_test_split(raw,test_size=0.75)\n",
    "non_validation_training1,non_validation_testing1 = train_test_split(non_validation,test_size=0.33,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_validation_training1['image_flat'] = non_validation_training1['image'].apply(lambda x: np.array(x).reshape(-1))\n",
    "non_validation_testing1['image_flat'] = non_validation_testing1['image'].apply(lambda x: np.array(x).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for performance metrics\n",
    "metrics_dict = {}\n",
    "metrics_dict = {\n",
    "    '0_vs_1' : { # task name (0 vs 1 classifier)\n",
    "    \n",
    "        'xgboost': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'neural_network': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(task, model_name, metrics_dict):\n",
    "    \"\"\"Display performance metrics and confusion matrix for a model.\"\"\"\n",
    "    metrics_df = pd.DataFrame()\n",
    "    cm_df = pd.DataFrame()\n",
    "    for key, value in metrics_dict[task][model_name].items():\n",
    "        if type(value) == np.ndarray:\n",
    "            cm_df = pd.DataFrame(value, index=['actual 0', 'actual 1'], columns=['predicted 0', 'predicted 1'])\n",
    "        else:\n",
    "            metrics_df[key] = [value]\n",
    "    display(Markdown(f'# Performance Metrics: {model_name}'))\n",
    "    display(metrics_df)\n",
    "    display(Markdown(f'# Confusion Matrix: {model_name}'))\n",
    "    display(cm_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.895717</td>\n",
       "      <td>0.91009</td>\n",
       "      <td>0.880635</td>\n",
       "      <td>0.89512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall       f1\n",
       "0  0.895717    0.91009  0.880635  0.89512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>90830</td>\n",
       "      <td>8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>12156</td>\n",
       "      <td>89683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        90830         8860\n",
       "actual 1        12156        89683"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "task = '0_vs_1'\n",
    "model_name = 'random_forest'\n",
    "metrics_dict[task] = {model_name: {}}\n",
    "\n",
    "# Initialize random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(non_validation_training1['image_flat'].tolist(), non_validation_training1['class'])\n",
    "y_pred = rf_clf.predict(non_validation_testing1['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(non_validation_testing1['class'], y_pred)\n",
    "prec = precision_score(non_validation_testing1['class'], y_pred)\n",
    "rec = recall_score(non_validation_testing1['class'], y_pred)\n",
    "f1 = f1_score(non_validation_testing1['class'], y_pred)\n",
    "cm = confusion_matrix(non_validation_testing1['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: xgboost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878266</td>\n",
       "      <td>0.888137</td>\n",
       "      <td>0.868488</td>\n",
       "      <td>0.878203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.878266   0.888137  0.868488  0.878203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: xgboost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>88550</td>\n",
       "      <td>11140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>13393</td>\n",
       "      <td>88446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        88550        11140\n",
       "actual 1        13393        88446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, Markdown\n",
    "# 0 vs 1 Classifier: XGBoost\n",
    "task = '0_vs_1'\n",
    "model_name = 'xgboost'\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate model\n",
    "xgb_clf.fit(non_validation_training1['image_flat'].tolist(), non_validation_training1['class'])\n",
    "y_pred = xgb_clf.predict(non_validation_testing1['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(non_validation_testing1['class'], y_pred)\n",
    "prec = precision_score(non_validation_testing1['class'], y_pred)\n",
    "rec = recall_score(non_validation_testing1['class'], y_pred)\n",
    "f1 = f1_score(non_validation_testing1['class'], y_pred)\n",
    "cm = confusion_matrix(non_validation_testing1['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>image_flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220717</th>\n",
       "      <td>55</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245086</th>\n",
       "      <td>26</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104012</th>\n",
       "      <td>30</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173526</th>\n",
       "      <td>25</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303479</th>\n",
       "      <td>8</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134071</th>\n",
       "      <td>22</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222528</th>\n",
       "      <td>58</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>22</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>5</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415484</th>\n",
       "      <td>7</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409163 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                              image class  \\\n",
       "220717     55  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "245086     26  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "104012     30  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "173526     25  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "303479      8  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     0   \n",
       "...       ...                                                ...   ...   \n",
       "134071     22  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "222528     58  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "4168       22  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     1   \n",
       "836         5  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     0   \n",
       "415484      7  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     0   \n",
       "\n",
       "                                               image_flat  \n",
       "220717  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "245086  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "104012  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "173526  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "303479  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "134071  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "222528  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4168    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "836     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "415484  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[409163 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_validation_training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: logistic_regression"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736723</td>\n",
       "      <td>0.749226</td>\n",
       "      <td>0.719989</td>\n",
       "      <td>0.734317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.736723   0.749226  0.719989  0.734317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: logistic_regression"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>75148</td>\n",
       "      <td>24542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>28516</td>\n",
       "      <td>73323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        75148        24542\n",
       "actual 1        28516        73323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 0 vs 1 Classifier: Logistic Regression \n",
    "task = '0_vs_1'\n",
    "model_name = 'logistic_regression'\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "# When running without scaling the data, the model does not converge\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(non_validation_training1['image_flat'].tolist())\n",
    "valid_scaled = scaler.transform(non_validation_testing1['image_flat'].tolist())\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train and evaluate model\n",
    "lr_clf.fit(train_scaled, non_validation_training1['class'])\n",
    "y_pred = lr_clf.predict(valid_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(non_validation_testing1['class'], y_pred)\n",
    "prec = precision_score(non_validation_testing1['class'], y_pred)\n",
    "rec = recall_score(non_validation_testing1['class'], y_pred)\n",
    "f1 = f1_score(non_validation_testing1['class'], y_pred)\n",
    "cm = confusion_matrix(non_validation_testing1['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run all the models on a different training and testing set\n",
    "validation,non_validation = train_test_split(raw,test_size=0.9)\n",
    "non_validation_training2,non_validation_testing2 = train_test_split(non_validation,test_size=0.1,random_state=42)\n",
    "non_validation_training2['image_flat'] = non_validation_training2['image'].apply(lambda x: np.array(x).reshape(-1))\n",
    "non_validation_testing2['image_flat'] = non_validation_testing2['image'].apply(lambda x: np.array(x).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898448</td>\n",
       "      <td>0.915899</td>\n",
       "      <td>0.879959</td>\n",
       "      <td>0.897569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.898448   0.915899  0.879959  0.897569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>33235</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>4448</td>\n",
       "      <td>32606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        33235         2994\n",
       "actual 1         4448        32606"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "task = '0_vs_1'\n",
    "model_name = 'random_forest'\n",
    "metrics_dict[task] = {model_name: {}}\n",
    "\n",
    "# Initialize random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(non_validation_training2['image_flat'].tolist(), non_validation_training2['class'])\n",
    "y_pred = rf_clf.predict(non_validation_testing2['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(non_validation_testing2['class'], y_pred)\n",
    "prec = precision_score(non_validation_testing2['class'], y_pred)\n",
    "rec = recall_score(non_validation_testing2['class'], y_pred)\n",
    "f1 = f1_score(non_validation_testing2['class'], y_pred)\n",
    "cm = confusion_matrix(non_validation_testing2['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: xgboost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.877789</td>\n",
       "      <td>0.892321</td>\n",
       "      <td>0.862363</td>\n",
       "      <td>0.877086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.877789   0.892321  0.862363  0.877086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: xgboost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>32373</td>\n",
       "      <td>3856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>5100</td>\n",
       "      <td>31954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        32373         3856\n",
       "actual 1         5100        31954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, Markdown\n",
    "# 0 vs 1 Classifier: XGBoost\n",
    "task = '0_vs_1'\n",
    "model_name = 'xgboost'\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate model\n",
    "xgb_clf.fit(non_validation_training2['image_flat'].tolist(), non_validation_training2['class'])\n",
    "y_pred = xgb_clf.predict(non_validation_testing2['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(non_validation_testing2['class'], y_pred)\n",
    "prec = precision_score(non_validation_testing2['class'], y_pred)\n",
    "rec = recall_score(non_validation_testing2['class'], y_pred)\n",
    "f1 = f1_score(non_validation_testing2['class'], y_pred)\n",
    "cm = confusion_matrix(non_validation_testing2['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: logistic_regression"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.737647</td>\n",
       "      <td>0.751652</td>\n",
       "      <td>0.718546</td>\n",
       "      <td>0.734726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.737647   0.751652  0.718546  0.734726"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: logistic_regression"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>27432</td>\n",
       "      <td>8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>10429</td>\n",
       "      <td>26625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        27432         8797\n",
       "actual 1        10429        26625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 0 vs 1 Classifier: Logistic Regression \n",
    "task = '0_vs_1'\n",
    "model_name = 'logistic_regression'\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "# When running without scaling the data, the model does not converge\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(non_validation_training2['image_flat'].tolist())\n",
    "valid_scaled = scaler.transform(non_validation_testing2['image_flat'].tolist())\n",
    "\n",
    "# Initialize logistic regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train and evaluate model\n",
    "lr_clf.fit(train_scaled, non_validation_training2['class'])\n",
    "y_pred = lr_clf.predict(valid_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(non_validation_testing2['class'], y_pred)\n",
    "prec = precision_score(non_validation_testing2['class'], y_pred)\n",
    "rec = recall_score(non_validation_testing2['class'], y_pred)\n",
    "f1 = f1_score(non_validation_testing2['class'], y_pred)\n",
    "cm = confusion_matrix(non_validation_testing2['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.885865</td>\n",
       "      <td>0.900288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.901099    0.91519  0.885865  0.900288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: random_forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>37017</td>\n",
       "      <td>3369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>4684</td>\n",
       "      <td>36355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0        37017         3369\n",
       "actual 1         4684        36355"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the best model is random forest, which will be tested in the validation set\n",
    "validation['image_flat'] = validation['image'].apply(lambda x: np.array(x).reshape(-1))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "task = '0_vs_1'\n",
    "model_name = 'random_forest'\n",
    "metrics_dict[task] = {model_name: {}}\n",
    "\n",
    "# Initialize random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(non_validation_training2['image_flat'].tolist(), non_validation_training2['class'])\n",
    "y_pred = rf_clf.predict(validation['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(validation['class'], y_pred)\n",
    "prec = precision_score(validation['class'], y_pred)\n",
    "rec = recall_score(validation['class'], y_pred)\n",
    "f1 = f1_score(validation['class'], y_pred)\n",
    "cm = confusion_matrix(validation['class'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the winner model is random forest in binary outcome classification, its accuracy is always close to 90% for both testing and validation test. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
